# kitoboy-ml

Этот репозиторий содержит ML-часть проекта Kitoboy. Здесь представлен код для обучения моделей, предобработки данных, управления разметкой и других инструментов для машинного обучения.

# Скрипты

Ниже приведено описание всех исполняемых скриптов. Эти скрипты находятся в директории `./src/scripts`.

## label_studio_cli.py

Скрипт предназначен для взаимодействия с Label Studio (далее LS). Позволяет загружать или развёртывать данные для разметки задач классификации, где интерфейс разметки представляет собой текст для аннотирования, набор меток и поле для комментария.

Необходимо предоставить файл настроек, в котором определяется хост с LS, а также словарь с портами в качестве ключей и соответствующими токенами доступа в качестве значений. По умолчанию он размещён в `reference/settings.yaml`. Идея заключается в использовании нескольких инстансов LS Community Edition на одном сервере, так как в этой версии LS невозможно делать разметку параллельно в одном проекте. Поэтому каждому разметчику выделяется свой LS-инстанс. Также можно использовать одну машину с несколькими проектами, распределёнными между разметчиками, если это соответствует вашим требованиям безопасности.

Скрипт имеет глобальные и конкретные аргументы. Глобальные определяют путь к настройкам, имя проекта в LS для взаимодействия и порт, на котором развернут LS. После этого необходимо выбрать режим работы: `get_annotation` или `deploy_project`.

Аргументы для `get_annotation`:
- `--output_file` — путь для сохранения данных из LS в виде csv.
- `--with_comments_only` — если задано, сохраняются только примеры, где поле для комментариев (TextArea) не пустое.
- `--store_source_json` — если задано, создаёт по тому же пути и имени файл `.json`, содержащий всю информацию, предоставленную LS.

Аргументы для `deploy_project`:
- `--task_file` — путь к файлу с исходными данными. Это должен быть csv-файл, где каждая строка — отдельная задача, или json-файл, соответствующий спецификации входных данных LS. Столбец с текстом для разметки должен называться `text`. Входные данные должны также содержать `data_id` — уникальный идентификатор каждого примера.
- `--interface_config` — путь к файлу со спецификацией интерфейса разметки.

Пример получения разметки (при условии, что файл настроек по умолчанию):

```bash
$ python src/scripts/label_studio_cli.py --port 9999 --project_name annotation_1 get_annotation --output_file annotated_data.csv 
```

Пример запуска проекта на разметку:

```bash
$ python src/scripts/label_studio_cli.py --port 9999 --project_name annotation_1 deploy_project --task_file data_for_annot.csv --interface_config labeling_interface.txt 
```

## aggregate_annotation.py

Скрипт выполняет агрегацию пересекающейся разметки. После сбора разметки проводится её агрегирование. Предназначен для совместного использования со скриптом `label_studio_cli.py`. Доступно три типа агрегации:
- equal — финальная метка устанавливается только если все N разметчиков выбрали одну и ту же метку
- maximum — классическая стратегия мажоритарного голосования
- soft — в случае мультиразметки разбивает метки в список и выбирает те, которые встречаются больше чем `num_annotators // 2 + 1` раз.

Логика скрипта — собрать csv-файлы с разметкой из одной директории и получить один файл с агрегированной разметкой. Входные файлы должны различаться по разделителю `_`, иметь номер итерации на позиции 3 (отсчёт с 0) и имя аннотатора в конце. Входные данные должны содержать столбцы `data_id`, `text` и `annotation`.

На выходе скрипт создаёт два файла: один с примерами, где агрегация прошла успешно (в названии присутствует `matched`), и один с примерами, где агрегация не смогла определить метку (`unmatched`).

Аргументы скрипта:
- `--src_dir` — директория для поиска csv-файлов.
- `--out_dir` — директория для хранения результата.
- `--agg_method_to_match` — метод агрегации, который будет использоваться для выделения совпавших примеров.
- `--postfix` — постфикс для имён результирующих файлов.
- `--use_only` — номера итераций для использования, разделённые точкой с запятой.

Пример запуска:

```bash
$ python src/scripts/aggregate_annotation.py --src_dir ./annot_data/test_part/ --out_dir ./annot_data/test_part/ --agg_method_to_match soft --postfix aggregated 
```

## `run_training.py`
Скрипт запускает процедуру обучения модели типа BERT. Обучение основано на классе `Trainer` из библиотеки `transformers`. Параметры и аргументы задаются через конфиги Hydra в директории `./conf`. Основной конфиг — `conf/training_config.yaml`, который включает следующие параметры:

- `defaults` — базовые секции конфигурации: датасет, предобработка, модель и настройки ClearML.
- `log_into_clearml` — флаг для включения логирования в платформу ClearML.
- `seed` — значение random seed для воспроизводимости.
- `experiment_name` — идентификатор текущего эксперимента.
- `output_dir` — путь для сохранения выходных данных и артефактов модели.
- `save_total_limit` — максимальное количество хранимых чекпойнтов (null — без ограничения).
- `remove_checkpoints` — удалять ли чекпойнты, не являющиеся лучшими.
- `logging_dir` — путь для хранения логов.
- `truncation` — включить ли усечение текста в токенизаторе.
- `padding` — включить ли паддинг в токенизаторе.
- `max_length` — максимальная длина последовательности для токенизатора.
- `test_run` — флаг тестового запуска (если True — обучение только на 16 случайных примерах).
- `metric_for_best_model` — имя метрики для выбора лучшей модели (должно начинаться с 'eval_').

Параметры для `conf/clearml/clearml.yaml`:

* `project` — название проекта в ClearML.
* `task_name` — идентификатор задачи (состоит из префикса "bert_training-" и имени эксперимента).
* `task_type` — тип задачи: "training", "inference", "custom".
* `output_uri` — базовый путь для выходных данных (по умолчанию пустой).
* `model_upload_dest` — путь для загрузки моделей, объединяет output_uri с "/models".

Параметры для `conf/dataset/base.yaml`:

- `dataset_id` — id датасета в ClearML.
- `download_from_clearml` — скачивать ли датасет из ClearML.
- `base_path` — корневая директория с файлами датасета.
- `label2id` — json-файл с отображением текстовых меток в числовые id.
- `text_col` — имя столбца с текстом.
- `label_col` — имя столбца с метками.
- `train_file` — csv-файл для обучения.
- `test_file` — csv-файл для теста.
- `eval_file` — csv-файл для валидации (опционально).
- `use_test_as_eval` — использовать test-файл для валидации, если нет eval-файла.
- `sep` — разделитель в csv-файлах.

Параметры для `conf/model/bert-stage0.yaml`:

* `model_path` — путь к предобученной трансформер-модели (например, DeepPavlov/rubert-base-cased).
* `freeze_encoder` — замораживать ли слои энкодера при обучении.
* `epoch` — количество эпох обучения.
* `batch_size_train` — размер батча для обучения.
* `batch_size_eval` — размер батча для валидации.
* `weight_decay` — коэффициент регуляризации.
* `learning_rate` — скорость обучения.
* `save_total_limit` — максимальное число чекпойнтов.

Предобработка (`conf/preprocessing/preprocessing_v0.yaml`) основана на модуле `textfab`, который поддерживает внутренние и кастомные блоки обработки. Внутренние блоки перечисляются по ключу `primitives` (см. документацию textfab для списка), кастомные — по ключу `custom`.

Пример запуска обучения:

```bash 
$ python src/scripts/run_training.py
```

Так как используется Hydra, параметры можно переопределять при запуске (и другие возможности Hydra также доступны). Это особенно удобно, когда нужно изменить только датасет или имя эксперимента:

```bash
$ python src/scripts/run_training.py experiment_name=exp_name dataset.base_path=/data/another_dataset
```

## `run_hpo_optuna.py`

Экспериментальный скрипт для оптимизации гиперпараметров с помощью Optuna. Основан на скрипте `run_training.py`. Для использования необходимо задать пространство поиска параметров в строках 84-92. После этого просто запустите:

```bash
$ python src/scripts/run_hpo_optuna.py
```

## `pretrain_bert.py` и `pretrain_gpt.py`

Эти скрипты предназначены для предобучения моделей типа BERT и GPT с базовыми конфигами `config/pretrain_config_bert.yaml` и `config/pretrain_config_gpt.yaml` соответственно. Структура конфигов похожа на таковую в `run_training.py`, но содержит дополнительные гиперпараметры, специфичные для предобучения.

Для BERT:
- mlm_probability — вероятность маскированного языкового моделирования (MLM).
- gradient_accumulation_steps — число батчей до шага оптимизации.

Для GPT:
- max_len — максимальная длина текста, подаваемого на вход модели.

Примеры запуска:

```bash 
$ python src/scripts/pretrain_bert.py
$ python src/scripts/pretrain_gpt.py

```

## validate_puplished_models.py

Скрипт позволяет загрузить опубликованные модели и датасеты с HuggingFace по заданным repo id и провести валидацию по метрикам.
Опубликованные repo id для каждой конфигурации (Antisuisidal и Presuisidal) приведены в разделе "Опубликованные модели и датасеты" ниже. Важно использовать подходящий датасет для соответствующей модели.

Пример валидации модели antisuisidal:

```bash 
$ python src/scripts/validate_published_models.py --dataset_hf_repo_id=psytechlab/antisuisidal_dataset --model_hf_repo_id=psytechlab/antisuisidal_model
```
        
Пример валидации модели presuisidal:      

```bash 
$ python src/scripts/validate_published_models.py --dataset_hf_repo_id=psytechlab/presuisidal_dataset --model_hf_repo_id=psytechlab/presuisidal_model
```

### Опубликованные модели и датасеты

|  Конфигурация |Датасет  |  Модель |
|---|---|---|
| Antisuisidal  |  https://huggingface.co/datasets/psytechlab/antisuisidal_dataset | https://huggingface.co/psytechlab/antisuisidal_model  |   
| Presuisidal  |  https://huggingface.co/datasets/psytechlab/antisuisidal_dataset |  https://huggingface.co/psytechlab/presuisidal_model |   |   

# Парсеры

В этой директории находятся различные парсеры, разработанные для сбора данных для разметки пресуицидальных и антисуицидальных сигналов. Включает парсеры для:

* vk.com
* 2ch.*
* archivach.*
* palata6.net
* pobedish.ru
* psyche.guru

# Метрики

В этой директории реализованы различные метрики. На данный момент реализованы:
- Self-BLEU — измеряет лексическое разнообразие.
- Distinct-N — измеряет лексическое разнообразие.
- Набор парных метрик расстояния для векторов:
  - Remote Clique
  - Chamfer distance
  - Дисперсия минимального остовного дерева
  - Sparseness
  - Span metric

# Contrib

Директория с кодом сторонних разработчиков, сохранённым "как есть", если он работает корректно.

- cartography — код для картирования датасета.
- topmine — алгоритм для поиска ключевых фраз в тексте.
- v_info — вычисляет v-usable информацию для датасета.
